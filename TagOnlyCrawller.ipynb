{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException, TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TagCrawller:\n",
    "\n",
    "    #크롤러 객체 초기화\n",
    "    def __init__(self, chromedriver_path, original_file_path, url_csv_filepath, tag_csv_filepath, c_num, total_c_num):\n",
    "        self.driver = webdriver.Chrome(chromedriver_path)\n",
    "        self.original_file_path = original_file_path\n",
    "        self.url_csv_filepath = url_csv_filepath\n",
    "        self.tag_csv_filepath = tag_csv_filepath\n",
    "        self.c_num = c_num\n",
    "        self.total_c_num = total_c_num\n",
    "        self.CNT = 0\n",
    "   \n",
    "    def make_indi_file(self):\n",
    "        f = open(self.original_file_path, 'r', encoding='utf-8')\n",
    "        url_list = csv.reader(f)\n",
    "        \n",
    "        total_line_cnt = 0 # 행수\n",
    "        total_val_cnt = 0 # 총 url 수\n",
    "        \n",
    "        for line in url_list:\n",
    "            total_line_cnt+=1\n",
    "            for value in line:\n",
    "                total_val_cnt+=1\n",
    "                \n",
    "        f.seek(0)\n",
    "        \n",
    "        share_val = total_line_cnt // self.total_c_num\n",
    "        share_tot_val = total_val_cnt // self.total_c_num\n",
    "        \n",
    "        start_num = share_val * (self.c_num-1)\n",
    "        self.start_num = share_tot_val * (self.c_num-1)\n",
    "        \n",
    "        if self.c_num<self.total_c_num:\n",
    "            end_num = share_val * self.c_num - 1\n",
    "            self.end_num = share_tot_val * self.c_num - 1\n",
    "        \n",
    "        else:\n",
    "            end_num = total_line_cnt - 1\n",
    "            self.end_num = total_val_cnt - 1\n",
    "        \n",
    "        cnt = 0\n",
    "        for line in url_list:\n",
    "            if cnt < start_num:\n",
    "                cnt+=1\n",
    "                continue\n",
    "                    \n",
    "            if cnt == end_num:\n",
    "                break\n",
    "                \n",
    "            self.write_csv_url(line)\n",
    "            cnt+=1\n",
    "        \n",
    "        f.close()\n",
    "                \n",
    "                \n",
    "    #크롤러 객체 준비\n",
    "    def crawlling_ready(self):\n",
    "        self.make_indi_file()\n",
    "        self.read_csv()\n",
    "\n",
    "    # url크롤링이 완료된 후 수집된 url을 방문하며 \n",
    "    # 유저 ID , 포스팅 날짜, 해시태그 수집\n",
    "    def info_extractor(self,url):\n",
    "        self.driver.implicitly_wait(2)\n",
    "        self.driver.get(url)\n",
    "        source = self.driver.page_source \n",
    "        soup = BeautifulSoup(source, 'lxml') \n",
    "        \n",
    "        try:\n",
    "            hashtag_list = soup.findAll(\"a\", href=lambda value: value and value.startswith(\"/explore/tags\"))\n",
    "            posting_date = soup.find(\"time\")['title'] \n",
    "            userId = self.driver.find_element_by_xpath(\"//*[starts-with(@class, 'FPmhX')]\").text\n",
    "            \n",
    "            if len(hashtag_list)==0:\n",
    "                self.CNT+=1\n",
    "                return print(\"해쉬 없음!\")\n",
    "        \n",
    "        except NoSuchElementException:  \n",
    "            return print(\"NoSuchElementException!\")\n",
    "        \n",
    "        except StaleElementReferenceException:\n",
    "            return print(\"StaleElementReferenceException!\")\n",
    "        \n",
    "        except TypeError:\n",
    "            self.CNT+=1\n",
    "            return print(\"페이지 없음!\")\n",
    "       \n",
    "        h_list = self.tag_generator(hashtag_list)\n",
    "        hash_list = []\n",
    "        \n",
    "        for item in h_list:\n",
    "            hash_list.append(item)\n",
    "        \n",
    "        # 추후에 중복 처리를 위한 데이터\n",
    "        overall = userId + posting_date + str(hash_list) \n",
    "        \n",
    "        total_list = []\n",
    "        total_list.append(userId)\n",
    "        total_list.append(posting_date)\n",
    "        total_list.append(hash_list)\n",
    "        total_list.append(overall)\n",
    "        \n",
    "        self.write_csv_tag(total_list)\n",
    "        \n",
    "    \n",
    "    #url 을 저장하기 위한 csv 파일을 만든다     \n",
    "    def write_csv_url(self,list):\n",
    "        with codecs.open(self.url_csv_filepath,\"a\",\"utf-8\") as fp:\n",
    "            writer=csv.writer(fp,delimiter=\",\")\n",
    "            writer.writerow(list)\n",
    "     \n",
    "    #id, date, tag를 저장하기 위한 csv 파일을 만든다     \n",
    "    def write_csv_tag(self,list):\n",
    "        with codecs.open(self.tag_csv_filepath,\"a\",\"utf-8\") as fp:\n",
    "            writer=csv.writer(fp,delimiter=\",\")\n",
    "            writer.writerow(list)\n",
    "    \n",
    "    def tag_generator(self,hashtag_list):\n",
    "        for item in hashtag_list:\n",
    "            yield item.getText()\n",
    "    \n",
    "    def url_generator(self,url_list):    \n",
    "        for line in url_list:\n",
    "            for href in line:\n",
    "                url = 'https://www.instagram.com'+href\n",
    "                yield url\n",
    "    \n",
    "    # url 목록이 저장된 csv 파일을 읽으며 해당 url에 방문하여 크롤링한다\n",
    "    def read_csv(self):\n",
    "        print(\"-------------------%d번 크롤러 시작 : %d ~ %d---------------------\" %(self.c_num, self.start_num, self.end_num))\n",
    "        #f = open(self.url_csv_filepath, 'r', encoding='utf-8')\n",
    "        with open(self.url_csv_filepath, 'r', encoding='utf-8') as f:\n",
    "            url_list = csv.reader(f)\n",
    "            self.CNT = self.start_num\n",
    "            \n",
    "            for url in self.url_generator(url_list):\n",
    "                print(\"%d번...\" %self.CNT)\n",
    "\n",
    "                # url이 공백일 경우 예외처리\n",
    "                if url==\"\":\n",
    "                    continue\n",
    "\n",
    "                self.info_extractor(url)\n",
    "                self.CNT+=1\n",
    "            \n",
    "            print(\"--------------TAG 크롤링 끝!----------------\")\n",
    "            self.driver.close()\n",
    "        \n",
    "        #f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "크롤링할 키워드? : 제주도\n",
      "크롤러 총 몇 개? : 3\n",
      "몇 번 크롤러? : 1\n",
      "-------------------1번 크롤러 시작 : 0 ~ 27862---------------------\n",
      "0번...\n",
      "1번...\n",
      "2번...\n",
      "3번...\n",
      "페이지 없음!\n",
      "5번...\n",
      "6번...\n",
      "7번...\n",
      "8번...\n",
      "9번...\n",
      "10번...\n",
      "11번...\n",
      "12번...\n",
      "13번...\n",
      "14번...\n",
      "페이지 없음!\n",
      "16번...\n",
      "17번...\n",
      "18번...\n",
      "19번...\n",
      "20번...\n",
      "페이지 없음!\n",
      "22번...\n",
      "페이지 없음!\n",
      "24번...\n",
      "페이지 없음!\n",
      "26번...\n",
      "27번...\n",
      "페이지 없음!\n",
      "29번...\n",
      "30번...\n",
      "31번...\n",
      "페이지 없음!\n",
      "33번...\n",
      "34번...\n",
      "35번...\n",
      "36번...\n",
      "37번...\n",
      "38번...\n",
      "39번...\n",
      "40번...\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=68.0.3440.106)\n  (Driver info: chromedriver=2.40.565498 (ea082db3280dd6843ebfb08a625e3eb905c4f5ab),platform=Windows NT 6.1.7601 SP1 x86_64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4710b92a8fdf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mcrawller\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTagCrawller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchromedriver_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morginal_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl_csv_filepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag_csv_filepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_c_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mcrawller\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrawlling_ready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-f801ca346fcf>\u001b[0m in \u001b[0;36mcrawlling_ready\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcrawlling_ready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_indi_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;31m# url크롤링이 완료된 후 수집된 url을 방문하며\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-f801ca346fcf>\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    141\u001b[0m                     \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCNT\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-f801ca346fcf>\u001b[0m in \u001b[0;36minfo_extractor\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimplicitly_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mpage_source\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    670\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \"\"\"\n\u001b[1;32m--> 672\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_PAGE_SOURCE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    316\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=68.0.3440.106)\n  (Driver info: chromedriver=2.40.565498 (ea082db3280dd6843ebfb08a625e3eb905c4f5ab),platform=Windows NT 6.1.7601 SP1 x86_64)\n"
     ]
    }
   ],
   "source": [
    "keyword = input(\"크롤링할 키워드? : \") # url 해시태그\n",
    "orginal_file_path = 'C:/Users/acorn/weather_bigdata/original_url/url_'+keyword+'.csv'\n",
    "chromedriver_path = 'C:/Users/acorn/Desktop/weather/chromedriver_win32/chromedriver'\n",
    "\n",
    "total_c_num = int(input(\"크롤러 총 몇 개? : \"))\n",
    "c_num = int(input(\"몇 번 크롤러? : \"))\n",
    "\n",
    "url_csv_filepath = 'C:/Users/acorn/url_'+keyword+str(c_num)+'.csv'\n",
    "tag_csv_filepath = 'C:/Users/acorn/tag_'+keyword+str(c_num)+'.csv'\n",
    "\n",
    "crawller = TagCrawller(chromedriver_path, orginal_file_path, url_csv_filepath, tag_csv_filepath, c_num, total_c_num)\n",
    "crawller.crawlling_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
